{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, pickle\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the total amount of available images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9805 images will be used to train the network\n"
     ]
    }
   ],
   "source": [
    "nb_batches = 5\n",
    "nb_images = 0\n",
    "for i in range(nb_batches):\n",
    "    with open(\"pickles/labels\"+str(i)+\".pickle\", \"rb\") as file:\n",
    "        labels = pickle.load(file)\n",
    "        nb_images += len(labels)\n",
    "print(nb_images, \"images will be used to train the network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural network part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Clearing past graphs\n",
    "tf.reset_default_graph()   \n",
    "\n",
    "learning_rate = 0.02\n",
    "\n",
    "#placeholders definition\n",
    "input_data = tf.placeholder(tf.float32, (None, 128, 128, 3))\n",
    "input_labels = tf.placeholder(tf.int32, (None, 28))\n",
    "is_training = tf.placeholder(tf.bool)\n",
    "\n",
    "#layers definition\n",
    "conv1 = tf.layers.conv2d(input_data, 16, (5, 5), (1, 1), activation=tf.nn.relu)\n",
    "pool1 = tf.layers.max_pooling2d(conv1, (2, 2), (2, 2))\n",
    "add = tf.layers.\n",
    "\n",
    "conv2 = tf.layers.conv2d(pool1, 16, (5, 5), (1, 1), activation=tf.nn.relu)\n",
    "pool2 = tf.layers.max_pooling2d(conv2, (2, 2), (2, 2))\n",
    "\n",
    "conv3 = tf.layers.conv2d(pool2, 64, (3, 3), (1, 1), activation=tf.nn.relu)\n",
    "pool3 = tf.layers.max_pooling2d(conv3, (2, 2), (2, 2))\n",
    "\n",
    "conv4 = tf.layers.conv2d(pool3, 64, (3, 3), (1, 1), activation=tf.nn.relu)\n",
    "pool4 = tf.layers.max_pooling2d(conv4, (2, 2), (2, 2))\n",
    "\n",
    "flattened = tf.contrib.layers.flatten(pool4)\n",
    "\n",
    "# define fully-connected (or dense) layers\n",
    "dense1 = tf.layers.dense(flattened, 1000)\n",
    "drop1 = tf.layers.dropout(dense1, rate=0.5, training=is_training)\n",
    "\n",
    "dense2 = tf.layers.dense(drop1, 300)\n",
    "drop2 = tf.layers.dropout(dense2, rate=0.5, training=is_training)\n",
    "\n",
    "dense3 = tf.layers.dense(drop2, 100)\n",
    "drop3 = tf.layers.dropout(dense3, rate=0.5, training=is_training)\n",
    "\n",
    "logits = tf.layers.dense(drop3, 28)\n",
    "\n",
    "# define loss and training operation\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=input_labels, logits=logits))\n",
    "train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "\n",
    "# calcualte average accuracy over a batch of images\n",
    "accuracy = tf.reduce_mean(tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(input_labels, 1)), tf.float32))\n",
    "good_predictions = tf.cast(tf.reduce_sum(tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(input_labels, 1)), tf.float32)), tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9805 steps will be performed.\n",
      "step: 0 , loss: 4.0000954 , training accuracy: 0.04\n",
      "step: 50 , loss: 2.9077897 , training accuracy: 0.15\n",
      "step: 100 , loss: 2.8013184 , training accuracy: 0.14\n",
      "step: 150 , loss: 2.8902655 , training accuracy: 0.12\n",
      "step: 200 , loss: 2.7035992 , training accuracy: 0.2\n",
      "step: 250 , loss: 2.383393 , training accuracy: 0.29\n",
      "step: 300 , loss: 2.6205566 , training accuracy: 0.21\n",
      "step: 350 , loss: 2.6164308 , training accuracy: 0.16\n",
      "step: 400 , loss: 2.5116537 , training accuracy: 0.27\n",
      "step: 450 , loss: 2.4691286 , training accuracy: 0.21\n",
      "step: 500 , loss: 2.4649503 , training accuracy: 0.26\n",
      "step: 550 , loss: 2.4429471 , training accuracy: 0.27\n",
      "step: 600 , loss: 2.1128292 , training accuracy: 0.32\n",
      "step: 650 , loss: 2.3187685 , training accuracy: 0.28\n",
      "step: 700 , loss: 2.2526731 , training accuracy: 0.28\n",
      "step: 750 , loss: 2.2106674 , training accuracy: 0.32\n",
      "step: 800 , loss: 2.4697838 , training accuracy: 0.22\n",
      "step: 850 , loss: 2.4262679 , training accuracy: 0.23\n",
      "step: 900 , loss: 2.352874 , training accuracy: 0.29\n",
      "step: 950 , loss: 2.2173378 , training accuracy: 0.27\n",
      "step: 1000 , loss: 2.3470688 , training accuracy: 0.28\n",
      "step: 1050 , loss: 2.2697835 , training accuracy: 0.33\n",
      "step: 1100 , loss: 2.3604996 , training accuracy: 0.27\n",
      "step: 1150 , loss: 2.2992947 , training accuracy: 0.3\n",
      "step: 1200 , loss: 2.1946602 , training accuracy: 0.25\n",
      "step: 1250 , loss: 2.2814434 , training accuracy: 0.28\n",
      "step: 1300 , loss: 2.2264853 , training accuracy: 0.24\n",
      "step: 1350 , loss: 2.2384727 , training accuracy: 0.22\n",
      "step: 1400 , loss: 2.2705216 , training accuracy: 0.24\n",
      "step: 1450 , loss: 2.1755452 , training accuracy: 0.32\n",
      "step: 1500 , loss: 2.136354 , training accuracy: 0.24\n",
      "step: 1550 , loss: 2.1426659 , training accuracy: 0.31\n",
      "step: 1600 , loss: 1.923385 , training accuracy: 0.37\n",
      "step: 1650 , loss: 1.9866476 , training accuracy: 0.38\n",
      "step: 1700 , loss: 1.970368 , training accuracy: 0.39\n",
      "step: 1750 , loss: 1.7577647 , training accuracy: 0.39\n",
      "step: 1800 , loss: 2.1309996 , training accuracy: 0.34\n",
      "step: 1850 , loss: 2.2468438 , training accuracy: 0.28\n",
      "step: 1900 , loss: 2.1865122 , training accuracy: 0.38\n",
      "step: 1950 , loss: 2.0285604 , training accuracy: 0.36\n",
      "step: 2000 , loss: 2.0681267 , training accuracy: 0.35\n",
      "step: 2050 , loss: 2.014975 , training accuracy: 0.33\n",
      "step: 2100 , loss: 1.8803145 , training accuracy: 0.35\n",
      "step: 2150 , loss: 1.9401295 , training accuracy: 0.36\n",
      "step: 2200 , loss: 2.3515704 , training accuracy: 0.31\n",
      "step: 2250 , loss: 1.9901855 , training accuracy: 0.4\n",
      "step: 2300 , loss: 1.730021 , training accuracy: 0.36\n",
      "step: 2350 , loss: 1.7825806 , training accuracy: 0.46\n",
      "step: 2400 , loss: 1.9403266 , training accuracy: 0.4\n",
      "step: 2450 , loss: 1.825217 , training accuracy: 0.38\n",
      "step: 2500 , loss: 1.9381061 , training accuracy: 0.32\n",
      "step: 2550 , loss: 1.8135799 , training accuracy: 0.44\n",
      "step: 2600 , loss: 1.6941674 , training accuracy: 0.46\n",
      "step: 2650 , loss: 1.737853 , training accuracy: 0.41\n",
      "step: 2700 , loss: 1.837814 , training accuracy: 0.45\n",
      "step: 2750 , loss: 1.8170683 , training accuracy: 0.46\n",
      "step: 2800 , loss: 1.7139096 , training accuracy: 0.44\n",
      "step: 2850 , loss: 2.0852919 , training accuracy: 0.38\n",
      "step: 2900 , loss: 1.8441032 , training accuracy: 0.43\n",
      "step: 2950 , loss: 1.835841 , training accuracy: 0.37\n",
      "step: 3000 , loss: 1.658416 , training accuracy: 0.49\n",
      "step: 3050 , loss: 1.747314 , training accuracy: 0.38\n",
      "step: 3100 , loss: 1.8863176 , training accuracy: 0.39\n",
      "step: 3150 , loss: 1.8175033 , training accuracy: 0.46\n",
      "step: 3200 , loss: 1.533873 , training accuracy: 0.51\n",
      "step: 3250 , loss: 1.5296968 , training accuracy: 0.55\n",
      "step: 3300 , loss: 1.7197785 , training accuracy: 0.52\n",
      "step: 3350 , loss: 1.6770471 , training accuracy: 0.46\n",
      "step: 3400 , loss: 1.6216778 , training accuracy: 0.51\n",
      "step: 3450 , loss: 1.4926184 , training accuracy: 0.46\n",
      "step: 3500 , loss: 1.733271 , training accuracy: 0.43\n",
      "step: 3550 , loss: 1.6026568 , training accuracy: 0.42\n",
      "step: 3600 , loss: 1.5197948 , training accuracy: 0.5\n",
      "step: 3650 , loss: 1.7721453 , training accuracy: 0.42\n",
      "step: 3700 , loss: 1.6934996 , training accuracy: 0.45\n",
      "step: 3750 , loss: 1.4293404 , training accuracy: 0.52\n",
      "step: 3800 , loss: 1.6098922 , training accuracy: 0.48\n",
      "step: 3850 , loss: 1.5538812 , training accuracy: 0.54\n",
      "step: 3900 , loss: 1.5541683 , training accuracy: 0.47\n",
      "step: 3950 , loss: 1.4250721 , training accuracy: 0.51\n",
      "step: 4000 , loss: 1.4698312 , training accuracy: 0.53\n",
      "step: 4050 , loss: 1.4330707 , training accuracy: 0.51\n",
      "step: 4100 , loss: 1.2284776 , training accuracy: 0.66\n",
      "step: 4150 , loss: 1.6219275 , training accuracy: 0.54\n",
      "step: 4200 , loss: 1.6830083 , training accuracy: 0.49\n",
      "step: 4250 , loss: 1.3898604 , training accuracy: 0.54\n",
      "step: 4300 , loss: 1.6014931 , training accuracy: 0.47\n",
      "step: 4350 , loss: 1.3263574 , training accuracy: 0.54\n",
      "step: 4400 , loss: 1.543682 , training accuracy: 0.48\n",
      "step: 4450 , loss: 1.1167618 , training accuracy: 0.68\n",
      "step: 4500 , loss: 1.4927812 , training accuracy: 0.54\n",
      "step: 4550 , loss: 1.311462 , training accuracy: 0.52\n",
      "step: 4600 , loss: 2.2889676 , training accuracy: 0.38\n",
      "step: 4650 , loss: 1.1407429 , training accuracy: 0.59\n",
      "step: 4700 , loss: 1.4435097 , training accuracy: 0.46\n",
      "step: 4750 , loss: 1.354683 , training accuracy: 0.51\n",
      "step: 4800 , loss: 0.97415715 , training accuracy: 0.7\n",
      "step: 4850 , loss: 1.2167695 , training accuracy: 0.61\n",
      "step: 4900 , loss: 1.2907048 , training accuracy: 0.6\n",
      "step: 4950 , loss: 1.2257024 , training accuracy: 0.59\n",
      "step: 5000 , loss: 1.1437163 , training accuracy: 0.61\n",
      "step: 5050 , loss: 1.4218832 , training accuracy: 0.56\n",
      "step: 5100 , loss: 1.3679241 , training accuracy: 0.53\n",
      "step: 5150 , loss: 1.0001235 , training accuracy: 0.68\n",
      "step: 5200 , loss: 1.656915 , training accuracy: 0.48\n",
      "step: 5250 , loss: 1.5675474 , training accuracy: 0.48\n",
      "step: 5300 , loss: 1.1066642 , training accuracy: 0.63\n",
      "step: 5350 , loss: 1.3087865 , training accuracy: 0.57\n",
      "step: 5400 , loss: 1.3356392 , training accuracy: 0.63\n",
      "step: 5450 , loss: 1.4080946 , training accuracy: 0.51\n",
      "step: 5500 , loss: 0.8037609 , training accuracy: 0.77\n",
      "step: 5550 , loss: 1.5858452 , training accuracy: 0.52\n",
      "step: 5600 , loss: 1.5314518 , training accuracy: 0.55\n",
      "step: 5650 , loss: 1.1063051 , training accuracy: 0.63\n",
      "step: 5700 , loss: 1.2237749 , training accuracy: 0.61\n",
      "step: 5750 , loss: 1.038425 , training accuracy: 0.67\n",
      "step: 5800 , loss: 1.2555403 , training accuracy: 0.58\n",
      "step: 5850 , loss: 1.0027109 , training accuracy: 0.68\n",
      "step: 5900 , loss: 1.5167826 , training accuracy: 0.57\n",
      "step: 5950 , loss: 1.1168594 , training accuracy: 0.62\n",
      "step: 6000 , loss: 1.0169431 , training accuracy: 0.65\n",
      "step: 6050 , loss: 0.7919064 , training accuracy: 0.73\n",
      "step: 6100 , loss: 1.9660163 , training accuracy: 0.43\n",
      "step: 6150 , loss: 1.0060161 , training accuracy: 0.62\n",
      "step: 6200 , loss: 1.139993 , training accuracy: 0.69\n",
      "step: 6250 , loss: 1.107077 , training accuracy: 0.66\n",
      "step: 6300 , loss: 1.1678132 , training accuracy: 0.65\n",
      "step: 6350 , loss: 1.2028534 , training accuracy: 0.64\n",
      "step: 6400 , loss: 1.0690377 , training accuracy: 0.67\n",
      "step: 6450 , loss: 0.80019355 , training accuracy: 0.7\n",
      "step: 6500 , loss: 0.8181823 , training accuracy: 0.75\n",
      "step: 6550 , loss: 0.90591276 , training accuracy: 0.67\n",
      "step: 6600 , loss: 0.8705679 , training accuracy: 0.73\n",
      "step: 6650 , loss: 0.8016204 , training accuracy: 0.7\n",
      "step: 6700 , loss: 0.7023921 , training accuracy: 0.76\n",
      "step: 6750 , loss: 1.08575 , training accuracy: 0.63\n",
      "step: 6800 , loss: 0.44331247 , training accuracy: 0.87\n",
      "step: 6850 , loss: 1.0491185 , training accuracy: 0.64\n",
      "step: 6900 , loss: 1.0150595 , training accuracy: 0.68\n",
      "step: 6950 , loss: 0.5358803 , training accuracy: 0.85\n",
      "step: 7000 , loss: 0.5908548 , training accuracy: 0.84\n",
      "step: 7050 , loss: 0.73502 , training accuracy: 0.68\n",
      "step: 7100 , loss: 0.6977101 , training accuracy: 0.79\n",
      "step: 7150 , loss: 0.4407779 , training accuracy: 0.89\n",
      "step: 7200 , loss: 0.6650655 , training accuracy: 0.77\n",
      "step: 7250 , loss: 1.0023162 , training accuracy: 0.65\n",
      "step: 7300 , loss: 0.73727053 , training accuracy: 0.78\n",
      "step: 7350 , loss: 0.67632914 , training accuracy: 0.78\n",
      "step: 7400 , loss: 0.5256544 , training accuracy: 0.84\n",
      "step: 7450 , loss: 0.6116895 , training accuracy: 0.8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 7500 , loss: 0.3806504 , training accuracy: 0.89\n",
      "step: 7550 , loss: 0.72362113 , training accuracy: 0.76\n",
      "step: 7600 , loss: 0.6316234 , training accuracy: 0.83\n",
      "step: 7650 , loss: 0.5271745 , training accuracy: 0.8\n",
      "step: 7700 , loss: 0.5670472 , training accuracy: 0.84\n",
      "step: 7750 , loss: 0.6252847 , training accuracy: 0.81\n",
      "step: 7800 , loss: 0.5468813 , training accuracy: 0.82\n",
      "step: 7850 , loss: 0.47613975 , training accuracy: 0.84\n",
      "step: 7900 , loss: 1.8097408 , training accuracy: 0.5\n",
      "step: 7950 , loss: 0.6186912 , training accuracy: 0.74\n",
      "step: 8000 , loss: 0.6189581 , training accuracy: 0.82\n",
      "step: 8050 , loss: 0.79415923 , training accuracy: 0.76\n",
      "step: 8100 , loss: 0.4114903 , training accuracy: 0.83\n",
      "step: 8150 , loss: 0.46230522 , training accuracy: 0.81\n",
      "step: 8200 , loss: 0.37399998 , training accuracy: 0.9\n",
      "step: 8250 , loss: 0.47374997 , training accuracy: 0.81\n",
      "step: 8300 , loss: 0.6144824 , training accuracy: 0.77\n",
      "step: 8350 , loss: 0.8974759 , training accuracy: 0.68\n",
      "step: 8400 , loss: 0.9410794 , training accuracy: 0.74\n",
      "step: 8450 , loss: 0.5362127 , training accuracy: 0.87\n",
      "step: 8500 , loss: 0.43968606 , training accuracy: 0.86\n",
      "step: 8550 , loss: 0.6423594 , training accuracy: 0.86\n",
      "step: 8600 , loss: 0.38219142 , training accuracy: 0.84\n",
      "step: 8650 , loss: 0.67721605 , training accuracy: 0.77\n",
      "step: 8700 , loss: 0.43771118 , training accuracy: 0.86\n",
      "step: 8750 , loss: 0.48529083 , training accuracy: 0.82\n",
      "step: 8800 , loss: 0.523678 , training accuracy: 0.83\n",
      "step: 8850 , loss: 0.3609942 , training accuracy: 0.88\n",
      "step: 8900 , loss: 0.590796 , training accuracy: 0.81\n",
      "step: 8950 , loss: 0.33765525 , training accuracy: 0.87\n",
      "step: 9000 , loss: 0.4769002 , training accuracy: 0.86\n",
      "step: 9050 , loss: 0.53242785 , training accuracy: 0.83\n",
      "step: 9100 , loss: 0.3116535 , training accuracy: 0.89\n",
      "step: 9150 , loss: 0.4217991 , training accuracy: 0.83\n",
      "step: 9200 , loss: 0.610535 , training accuracy: 0.8\n",
      "step: 9250 , loss: 0.5382562 , training accuracy: 0.83\n",
      "step: 9300 , loss: 0.5641048 , training accuracy: 0.77\n",
      "step: 9350 , loss: 0.61167246 , training accuracy: 0.83\n",
      "step: 9400 , loss: 0.5075787 , training accuracy: 0.87\n",
      "step: 9450 , loss: 0.34589496 , training accuracy: 0.89\n",
      "step: 9500 , loss: 0.3285839 , training accuracy: 0.9\n",
      "step: 9550 , loss: 0.28554595 , training accuracy: 0.9\n",
      "step: 9600 , loss: 0.33517542 , training accuracy: 0.88\n",
      "step: 9650 , loss: 0.32357925 , training accuracy: 0.88\n",
      "step: 9700 , loss: 0.5527781 , training accuracy: 0.82\n",
      "step: 9750 , loss: 0.3561978 , training accuracy: 0.88\n",
      "step: 9800 , loss: 0.28912026 , training accuracy: 0.9\n",
      "Training finished.\n",
      "Validation accuracy: 37.36%.\n"
     ]
    }
   ],
   "source": [
    "#defining parameters of training run\n",
    "epoch = 40\n",
    "sub_batch_size = 100\n",
    "nb_steps = nb_images * epoch // sub_batch_size\n",
    "log_frequency = 50\n",
    "batch_range = [i for i in range(nb_batches)]\n",
    "batch_indices = []\n",
    "for i in range(epoch):\n",
    "    batch_indices += batch_range\n",
    "    \n",
    "print(nb_steps, \"steps will be performed.\")\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    #Initialization\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    batch_run = 0\n",
    "    \n",
    "    for step_index in range(nb_steps):\n",
    "        #On first step\n",
    "        if step_index == 0:\n",
    "            with open(\"pickles/images0.pickle\", \"rb\") as file:\n",
    "                images = pickle.load(file)\n",
    "            with open(\"pickles/labels0.pickle\", \"rb\") as file:\n",
    "                labels = pickle.load(file)\n",
    "            sub_batch_index = 0\n",
    "            batch_size = len(labels)\n",
    "                \n",
    "        #If we are crossing images sets\n",
    "        elif (sub_batch_index + 1)* sub_batch_size > batch_size:\n",
    "            before_crossing_images = images[-(batch_size - (sub_batch_index-1)*sub_batch_size):]\n",
    "            before_crossing_labels = labels[-(batch_size - (sub_batch_index-1)*sub_batch_size):]\n",
    "            with open(\"pickles/images\"+str(batch_indices[batch_run])+\".pickle\", \"rb\") as file:\n",
    "                images = np.concatenate((before_crossing_images, pickle.load(file)))\n",
    "            with open(\"pickles/labels\"+str(batch_indices[batch_run])+\".pickle\", \"rb\") as file:\n",
    "                labels = np.concatenate((before_crossing_labels, pickle.load(file)))\n",
    "            sub_batch_index = 0\n",
    "            batch_size = len(labels)\n",
    "            batch_run += 1\n",
    "            \n",
    "        indices = [i for i in range(sub_batch_size*sub_batch_index, sub_batch_size*(sub_batch_index+1))]\n",
    "        \n",
    "        #performing training\n",
    "        batch_loss, batch_accuracy, _ = sess.run([loss, accuracy, train_op], feed_dict={\n",
    "            input_data: images.take(indices, axis=0),\n",
    "            input_labels: labels.take(indices, axis=0),\n",
    "            is_training: True\n",
    "            })\n",
    "            \n",
    "        #logging\n",
    "        if step_index % log_frequency == 0:\n",
    "            print('step:', step_index, ', loss:', batch_loss, ', training accuracy:', batch_accuracy)\n",
    "        \n",
    "        sub_batch_index += 1\n",
    "        \n",
    "    ### END OF TRAINING\n",
    "    \n",
    "    print(\"Training finished.\")\n",
    "    \n",
    "    with open(\"pickles/images6.pickle\", \"rb\") as file:\n",
    "        images = pickle.load(file)\n",
    "    with open(\"pickles/labels6.pickle\", \"rb\") as file:\n",
    "        labels = pickle.load(file)\n",
    "        \n",
    "    test_size = len(labels)\n",
    "    sub_batch_size = 20\n",
    "    total_correct = 0\n",
    "    \n",
    "    for step in range(test_size // sub_batch_size):\n",
    "        offset = step * sub_batch_size\n",
    "        batch_data = images[offset:(offset + sub_batch_size)]\n",
    "        batch_labels = labels[offset:(offset + sub_batch_size)]\n",
    "        \n",
    "        corrects = sess.run(good_predictions,feed_dict={\n",
    "            input_data: batch_data,\n",
    "            input_labels: batch_labels,\n",
    "            is_training: False\n",
    "        })\n",
    "        total_correct += corrects\n",
    "        \n",
    "    test_accuracy = 100.0 * (total_correct / test_size)\n",
    "\n",
    "    print(\"Validation accuracy: {0:.2f}%.\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
